---
name: review
description: "执行当前阶段审查。检查代码质量、测试覆盖、PRD 符合性。用户说'审查'/'检查'/'review'时自动触发。自动驱动模式下阶段完成后自动执行。"
argument-hint: "[filepath]"
context: fork
allowed-tools:
  - Read
  - Glob
  - Grep
  - Bash
  - Edit
hooks:
  Stop:
    - hooks:
        - type: command
          command: "echo '{\"hookSpecificOutput\":{\"additionalContext\":\"审查完成前确保：(1) 报告已写入 .claude/reviews/ (2) 所有检查项已标注通过/未通过\"}}'"
---

用法：`/review [文件路径]`

参数：$ARGUMENTS

---

## 核心原则

1. **Review 不是最后才做的事，而是每个阶段的退出门禁。**
2. **每个阶段的 Review 都必须检查 PRD 符合性：不多、不少、不改。**
3. **自动驱动模式下，Review 自动执行**：P3-P6 阶段工作完成后自动触发审查，通过则自动推进，无需用户操作。

错误越晚发现修复成本越高：需求阶段的错误到编码阶段修复成本 ×10，到部署阶段 ×100。
因此每个阶段结束时都必须执行该阶段的专项审查，确保产出物质量合格且严格符合 PRD 后才能推进。

---

## 工具辅助审查（生产级）

审查 = 真实工具链输出（客观数据）+ LLM 审查（主观判断）。

### 执行顺序
1. 自动检测项目类型（见 06-review-tools.md）
2. **检测并安装工具** — 检测所需工具是否已安装，未安装则自动安装
3. 运行对应工具，收集输出
4. 基于工具输出 + LLM 分析执行审查清单
5. 生成审查报告
6. **持久化**：将报告写入 .claude/reviews/P{n}-review-{时间}.md

---

## 执行逻辑

### 1. 自动识别当前阶段

读取 .claude/project-state.md 中的 `current_phase`，根据阶段选择对应的审查清单。

### 2. 确定审查范围

- **如果指定了文件路径**：审查指定文件（仅适用于 P3+ 阶段）
- **如果未指定文件**：审查当前阶段的全部产出物

---

## P1 需求分析 — 需求审查

### 审查清单
- [ ] **PRD 编号化**：每条需求是否有唯一编号（R1, R2, R3...）
- [ ] **完整性**：是否覆盖了用户提出的所有需求点，无遗漏
- [ ] **明确性**：每条需求是否有清晰的验收标准，无歧义表述
- [ ] **一致性**：需求之间是否存在矛盾或冲突
- [ ] **可行性**：每条需求在当前代码库/技术栈下是否可实现
- [ ] **范围边界**：是否明确列出了"不做"的事项
- [ ] **无自行添加**：需求清单是否仅包含用户提出的需求，Claude 没有自行添加需求
- [ ] **影响分析**：受影响的文件和模块是否已识别完整
- [ ] **风险识别**：技术风险和业务风险是否已列出
- [ ] **用户已确认**：PRD 是否已经用户明确确认
- [ ] **已写入 .claude/project-state.md**：PRD 是否已写入 `prd` 字段

### 输出格式
```
╔══════════════════════════════════════╗
║       P1 需求审查报告                ║
╚══════════════════════════════════════╝

📋 PRD 清单（共 {n} 条需求）：
  R1: {需求描述} — {验收标准}
  R2: {需求描述} — {验收标准}
  ...

🔒 范围排除项（不做的事）：
  - {排除项1}
  - {排除项2}

✅ / ❌ {逐项审查结果}

⚠️ 发现的问题：
  1. [严重程度] {问题描述} → {建议}

📊 结论：{通过 / 需补充后通过}
```

---

## P2 系统设计 — 设计审查

### 审查清单
- [ ] **最新文档已查阅**：是否通过 Context7 MCP 查询了涉及库/框架的最新官方文档，是否通过 WebSearch 搜索了当前最流行的设计方案
- [ ] **UI/UX 调研已完成**（如涉及 UI）：是否搜索了最新 UI/UX 设计趋势和流行交互模式
- [ ] **PRD 全覆盖**：逐条对照 PRD，设计方案是否覆盖每一条需求
- [ ] **无超出 PRD 的设计**：设计中是否存在 PRD 未要求的功能/接口/模块
- [ ] **架构合理性**：方案是否是当前场景下的合理选择，是否过度设计，**是否符合当前社区最佳实践**
- [ ] **原型设计**（如涉及 UI）：页面布局、组件结构、交互流程、视觉风格是否已完整定义
- [ ] **一致性**：设计是否与现有代码库的架构风格一致
- [ ] **接口设计**：API/函数接口是否清晰、参数是否合理，**是否使用最新推荐的接口模式**
- [ ] **数据流**：数据的流入、处理、流出路径是否清晰
- [ ] **错误处理策略**：异常和边界情况的处理方案是否已考虑
- [ ] **技术选型依据**：选型理由是否充分，是否评估了替代方案，**是否引用了最新文档**
- [ ] **实现步骤**：步骤分解是否合理，依赖关系是否明确
- [ ] **可测试性**：设计是否便于编写测试

### 输出格式
```
╔══════════════════════════════════════╗
║       P2 设计审查报告                ║
╚══════════════════════════════════════╝

📚 技术调研：
  Context7 查阅：{库1 最新文档}、{库2 最新文档}
  WebSearch 调研：{最新架构设计/最佳实践}
  状态：{✅ 已完成 / ❌ 未执行}

🎨 UI/UX 调研与原型设计（如涉及 UI）：
  设计趋势调研：{✅ 已完成 / ❌ 未执行 / ⬜ 不涉及 UI}
  原型设计：
    页面布局：{✅ 已定义 / ❌ 未定义}
    组件结构：{✅ 已定义 / ❌ 未定义}
    交互流程：{✅ 已定义 / ❌ 未定义}
    视觉风格：{✅ 已定义 / ❌ 未定义}

📋 PRD→设计映射：
  R1 → {设计模块/文件}  ✅
  R2 → {设计模块/文件}  ✅
  R3 → 未覆盖           ❌

🚫 超出 PRD 的设计：{无 / 列表}

🏗️ 架构方案审查：
  ✅ / ❌ {逐项检查结果}

⚠️ 发现的问题：
  1. [严重程度] {问题描述} → {建议}

📊 结论：{通过 / 需修改后通过}
```

---

## P3 编码实现 — 代码审查

### 审查范围
- 审查 .claude/project-state.md 中 `modified_files` 列表里的所有文件
- 如指定了文件路径，仅审查该文件

### 工具执行（P3 审查前必须运行）

**0. 工具检测与安装**：检测项目所需的审查工具是否已安装，未安装则自动安装（见 06-review-tools.md）

**重要：所有 Bash 命令必须写成单行，禁止换行。** 直接复制下方命令模板使用。

1. **Lint 检查**（按项目类型选一条执行）：
   - Node.js: `npx eslint . 2>&1; echo "LINT_EXIT=$?"`
   - Python: `ruff check . 2>&1; echo "LINT_EXIT=$?"`
   - Go: `go vet ./... 2>&1; echo "LINT_EXIT=$?"`
   - Rust: `cargo clippy 2>&1; echo "LINT_EXIT=$?"`
   - 0 error → ✅ | 有 error → 必须修复后重新审查 | warning 记录但不阻塞
2. **类型检查**（如适用，按项目类型选一条执行）：
   - Node.js: `npx tsc --noEmit 2>&1; echo "TSC_EXIT=$?"`
   - Python: `mypy . 2>&1; echo "MYPY_EXIT=$?"`
   - 0 error → ✅ | 有 error → 必须修复
3. **构建验证**（按项目类型选一条执行）：
   - Node.js: `npm run build 2>&1; echo "BUILD_EXIT=$?"`
   - Go: `go build ./... 2>&1; echo "BUILD_EXIT=$?"`
   - Rust: `cargo build 2>&1; echo "BUILD_EXIT=$?"`
   - 构建成功 → ✅ | 失败 → 必须修复
4. **依赖安全审计**（按项目类型选一条执行）：
   - Node.js: `npm audit 2>&1; echo "AUDIT_EXIT=$?"`
   - Python: `pip audit 2>&1; echo "AUDIT_EXIT=$?"`
   - Go: `govulncheck ./... 2>&1; echo "AUDIT_EXIT=$?"`
   - Rust: `cargo audit 2>&1; echo "AUDIT_EXIT=$?"`
   - 0 high/critical → ✅ | 有 high/critical → 记录为审查问题

工具未安装时：**自动安装**（见 06-review-tools.md 安装规则）。安装仍失败时：记录"⚠️ [工具名] 安装失败，跳过"，不阻塞审查。

### 审查清单

#### 3.0 最新 API 与 PRD 符合性（最优先检查）
- [ ] **最新 API 使用** — 代码是否使用了当前版本推荐的 API/方法，是否存在已废弃（deprecated）的调用
- [ ] **PRD 全实现** — 逐条对照 PRD，每条需求是否都已有对应代码
- [ ] **无 PRD 外代码** — 是否存在 PRD 未要求的功能、接口、参数、配置、优化
- [ ] 如发现多出的代码，标注其对应的 PRD 需求编号。对应不上的必须删除。

#### 3.1 设计符合性
- [ ] 代码实现是否与 P2 设计方案一致
- [ ] 是否有偏离设计的地方（如有，是否合理且已记录）

#### 3.2 代码质量
- [ ] 命名清晰、符合语言约定
- [ ] 函数单一职责、长度合理（≤50 行）
- [ ] 嵌套层级合理（≤3 层）
- [ ] 无魔法数字/字符串
- [ ] 无冗余代码或注释掉的代码
- [ ] 导入语句已清理
- [ ] 错误处理完善
- [ ] 代码格式一致

#### 3.3 安全性
- [ ] 无 SQL 注入风险
- [ ] 无 XSS 风险
- [ ] 无命令注入风险
- [ ] 无目录遍历风险
- [ ] 无硬编码的敏感信息（密码、密钥、token）
- [ ] 输入验证充分

#### 3.4 可维护性
- [ ] 代码可读性好
- [ ] 复杂逻辑有注释说明
- [ ] 模块职责清晰
- [ ] 符合项目已有的代码风格

### 输出格式
```
╔══════════════════════════════════════╗
║       P3 代码审查报告                ║
╚══════════════════════════════════════╝

📄 审查文件：{文件路径}

🔧 工具链检查：
  Lint：{✅ 0 errors / ❌ N errors, M warnings}
  Typecheck：{✅ 通过 / ❌ N errors / ⬜ 不适用}
  Build：{✅ 成功 / ❌ 失败}
  依赖审计：{✅ 无高危漏洞 / ⚠️ N 个漏洞}

0️⃣ 最新 API：{✅ 使用当前推荐 API / ⚠️ 存在废弃调用}
1️⃣ 设计符合性：{✅ 一致 / ⚠️ 有偏离}
2️⃣ 代码质量：{✅ 通过 / ⚠️ 有问题}
3️⃣ 安全性：{✅ 通过 / 🚨 有风险}
4️⃣ 可维护性：{✅ 通过 / ⚠️ 有问题}

⚠️ 发现的问题：
  1. [严重程度] {问题描述} → {建议}

📊 结论：{通过 / 需修改后通过}
```

### 未通过处理
- 严重/高优先级问题 → 必须在当前阶段内修复，修复后重新 `/review`
- 中/低优先级问题 → 记录到 `todo_items`，可在后续迭代处理

---

## P4 测试验证 — 测试审查

### 工具执行（P4 审查前必须运行）

**重要：所有 Bash 命令必须写成单行，禁止换行。** 直接复制下方命令模板使用。

#### 核心效率规则（必须遵守）

**测试只运行一次，从输出文件分析结果。禁止对同一测试文件/套件反复执行 `npx vitest run` / `npx jest` / `pytest` 等命令。**

每次测试运行都有编译+启动开销（Vitest/Jest 通常 5-15 秒），反复运行同一测试会导致审查极慢。

正确流程：
1. **运行一次** → 完整输出保存到临时文件
2. **从文件分析** → 用 Read 工具读取输出文件，提取通过/失败/覆盖率数据
3. **如有失败** → 用 Read 读取输出文件中的错误信息，**批量修复所有问题**，然后再运行一次验证
4. **整个审查最多运行 3 次测试**（首次 + 最多 2 次修复验证）

#### 步骤 1：运行测试并保存完整输出

按项目类型选一条执行（输出保存到临时文件）：
- Node.js (Jest): `npx jest --coverage 2>&1 | tee /tmp/sdlc-test-output.txt; echo "TEST_EXIT=${PIPESTATUS[0]}"`
- Node.js (Vitest): `npx vitest run --coverage 2>&1 | tee /tmp/sdlc-test-output.txt; echo "TEST_EXIT=${PIPESTATUS[0]}"`
- Python: `pytest --cov 2>&1 | tee /tmp/sdlc-test-output.txt; echo "TEST_EXIT=${PIPESTATUS[0]}"`
- Go: `go test -coverprofile=cover.out ./... 2>&1 | tee /tmp/sdlc-test-output.txt; echo "TEST_EXIT=${PIPESTATUS[0]}"`
- Rust: `cargo test 2>&1 | tee /tmp/sdlc-test-output.txt; echo "TEST_EXIT=${PIPESTATUS[0]}"`

#### 步骤 2：从输出文件分析结果

**禁止重新运行测试来查看结果。** 用 Read 工具读取 `/tmp/sdlc-test-output.txt`，从中提取：
- 通过数、失败数、跳过数
- 行覆盖率、分支覆盖率
- 失败测试的错误信息和堆栈

#### 步骤 3：修复失败（如有）

- 从步骤 2 读取的输出中**一次性收集所有失败信息**
- **批量修复**所有失败的测试/代码（不要修一个跑一次）
- 全部修复完成后，再运行一次测试验证（回到步骤 1）

#### 判定标准
- 全部通过 + 行覆盖率 ≥80% → ✅
- 有失败 → 必须修复（批量修复后重跑一次，不要逐个修复逐个跑）
- 覆盖率不足 → 记录为审查问题

#### 禁止行为
- ❌ 对同一测试文件运行 2 次以上 `npx vitest run` / `npx jest`
- ❌ 用 `-t "test name"` 单独运行某个测试用例（启动开销一样大）
- ❌ 用 `grep -E "FAIL|pass"` 过滤测试输出后再重跑来看别的信息
- ❌ 每修复一个测试就重跑一次

### 审查清单

#### 4.0 PRD 需求覆盖（最优先检查）
- [ ] **PRD 逐条对照** — 列出每条 PRD 需求，标注其对应的测试用例
- [ ] **每条 PRD 需求至少一个测试** — 不允许有未被测试验证的需求
- [ ] **无 PRD 外测试** — 测试用例是否仅验证 PRD 范围内的功能（不为 PRD 外代码补测试）

#### 4.1 测试覆盖度
- [ ] 所有新增/修改的公共函数都有对应测试
- [ ] 正常路径已覆盖
- [ ] 错误路径已覆盖
- [ ] 边界条件已覆盖（空值、极值、边界值）
- [ ] 关键业务逻辑覆盖率 ≥ 90%

#### 4.2 测试质量
- [ ] 遵循 AAA 模式（Arrange-Act-Assert）
- [ ] 测试命名清晰（"should X when Y" 格式）
- [ ] 每个测试只验证一个逻辑概念
- [ ] 测试之间相互独立，无顺序依赖
- [ ] Mock 使用合理（只 mock 外部依赖，不 mock 内部实现）

#### 4.3 测试结果
- [ ] 所有测试通过（零失败）
- [ ] 无被跳过(skip)的测试（除非有明确原因）
- [ ] 测试执行时间合理

#### 4.4 回归保护
- [ ] 修复 bug 时先写了能复现该 bug 的测试
- [ ] 修改代码后已有测试仍通过（无回归）

### 输出格式
```
╔══════════════════════════════════════╗
║       P4 测试审查报告                ║
╚══════════════════════════════════════╝

📋 PRD→测试映射：
  R1 → {测试文件:测试函数名}  ✅
  R2 → {测试文件:测试函数名}  ✅
  R3 → 未覆盖                 ❌

🧪 测试执行结果（真实数据）：
  命令：{实际执行的测试命令}
  通过：{n} / 失败：{n} / 跳过：{n}
  行覆盖率：{xx.x%} {≥80% → ✅ / <80% → ⚠️}
  分支覆盖率：{xx.x%}

🧪 测试覆盖度：{✅ 达标 / ⚠️ 不足}
   缺失覆盖：{列表}

📝 测试质量：{✅ 通过 / ⚠️ 有问题}
   {逐项检查结果}

⚠️ 发现的问题：
  1. [严重程度] {问题描述} → {建议}

📊 结论：{通过 / 需补充测试后通过}
```

### 未通过处理
- 覆盖率不足 → 补充测试，重新 `/review`（重新审查时测试仍只跑一次）
- 测试失败 → **从输出文件一次性收集所有失败信息，批量修复，再跑一次验证**，不要逐个修复逐个跑

---

## P5 集成审查 — 全局审查（最终关卡）

### 说明
P5 是部署前的最终审查，侧重于**跨文件/跨模块的全局视角**，检查单个阶段审查无法发现的系统级问题。

### 审查清单

#### 5.1 全局一致性
- [ ] 各模块间接口调用参数匹配
- [ ] 数据模型在各层（API → 业务逻辑 → 存储）间一致
- [ ] 错误处理策略在各模块间一致
- [ ] 命名风格在全项目范围内一致

#### 5.2 集成安全性
- [ ] 模块间数据传递是否有信任边界问题
- [ ] 权限检查是否在正确的层级执行
- [ ] 敏感信息是否在模块间安全传递

#### 5.3 性能全局视角
- [ ] 无 N+1 查询问题
- [ ] 无不必要的重复计算或重复 I/O
- [ ] 热路径（频繁执行的代码路径）性能是否可接受
- [ ] 内存使用是否合理

#### 5.4 PRD 四环追溯（最关键检查）
- [ ] **逐条 PRD 需求追溯** — 每条需求必须追溯到：PRD → 设计模块 → 代码文件:行号 → 测试用例
- [ ] **四环无断链** — 任何一条需求的四环中不得有缺失
- [ ] **无 PRD 外变更** — 不存在任何 PRD 未要求的功能代码、接口、配置

#### 5.5 变更完整性
- [ ] 所有 P2 设计均已落地
- [ ] 所有 P3 代码审查问题已修复
- [ ] 所有 P4 测试通过
- [ ] 无遗漏的 TODO/FIXME

### 输出格式
```
╔══════════════════════════════════════╗
║       P5 集成审查报告                ║
╚══════════════════════════════════════╝

🔗 全局一致性：{✅ 通过 / ⚠️ 有问题}
🔒 集成安全性：{✅ 通过 / 🚨 有风险}
⚡ 性能全局视角：{✅ 通过 / ⚠️ 有问题}
📋 PRD 四环追溯：{✅ 全部完整 / ❌ 有断链}

PRD 完整追溯表：
  R1: {需求描述}
      设计 → {模块/文件}
      代码 → {文件:行号}
      测试 → {测试文件:测试函数}
      状态：✅ 四环完整

  R2: {需求描述}
      设计 → {模块/文件}
      代码 → {文件:行号}
      测试 → 缺失
      状态：❌ 测试环断链

🚫 PRD 外变更：{无 / 列表}

⚠️ 发现的问题：
  1. [严重程度] {问题描述} → {建议}

📊 结论：{通过可部署 / 需回退修复}
```

### 未通过处理
- 需求遗漏 → 回退到 P3 实现，然后 P4 补测试
- 集成问题 → 回退到 P3 修复
- 全部通过 → 推进到 P6 部署

---

## P6 部署交付 — 交付审查

### 审查清单
- [ ] **交付物与 PRD 一致** — 提交的代码变更集合恰好覆盖 PRD 所有需求，不多不少
- [ ] Git commit message 符合 Conventional Commits 规范
- [ ] 提交粒度合理（每个 commit 一个逻辑变更）
- [ ] 无敏感信息被提交（.env、密钥、token）
- [ ] .gitignore 是否需要更新
- [ ] PR 描述完整（Summary、Changes、Test Plan）
- [ ] 文档是否需要更新（README、CHANGELOG 等）

### 输出格式
```
╔══════════════════════════════════════╗
║       P6 交付审查报告                ║
╚══════════════════════════════════════╝

📦 提交审查：{✅ 通过 / ⚠️ 有问题}
📝 文档审查：{✅ 已更新 / ⚠️ 需更新}

📊 结论：{可交付 / 需调整后交付}
```

---

## 审查报告持久化

审查完成后，将完整报告（含工具输出原文）用 Write 工具写入：

```
.claude/reviews/P{阶段}-review-{YYYYMMDD-HHmmss}.md
```

报告内容包含：阶段编号、审查时间、工具输出原文、LLM 审查结论、通过/未通过判定。

---

## 审查与阶段推进的关系

### 自动驱动模式（P3-P6）

```
当前阶段工作完成
     ↓
自动执行 /review
     ↓
  审查通过？ ──── 是 ──→ 自动推进到下一阶段，立即开始工作
     │
     否
     ↓
  自动修复问题 → 重新 /review（最多重试 3 次）
     │
  3 次仍未通过
     ↓
  停下向用户报告，请求指导
```

### 用户确认模式（P1-P2）

```
当前阶段工作完成
     ↓
向用户展示产出物（PRD / 设计方案）
     ↓
用户确认？ ──── 是 ──→ 自动执行 /review → 通过 → 自动推进
     │
     否/需修改
     ↓
根据用户反馈修改 → 重新展示给用户
```

### 手动触发

用户随时可以手动执行 `/review` 进行中间检查。
也可以手动执行 `/phase next` 强制推进。
